{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02c5344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset -d] [--model -m] [--test]\n",
      "                             [--retrain] [--less]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\admin\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3284d86815cc84fdddab120aaeae52d0773f18835.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from src.models import *\n",
    "from src.constants import *\n",
    "from src.plotting import *\n",
    "from src.pot import *\n",
    "from src.utils import *\n",
    "from src.diagnosis import *\n",
    "from src.merlin import *\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "# from beepy import beep\n",
    "\n",
    "def convert_to_windows(data, model):\n",
    "\twindows = []; w_size = model.n_window\n",
    "\tfor i, g in enumerate(data): \n",
    "\t\tif i >= w_size: w = data[i-w_size:i]\n",
    "\t\telse: w = torch.cat([data[0].repeat(w_size-i, 1), data[0:i]])\n",
    "\t\twindows.append(w if 'TranAD' in args.model or 'Attention' in args.model else w.view(-1))\n",
    "\treturn torch.stack(windows)\n",
    "\n",
    "def load_dataset(dataset):\n",
    "\tfolder = os.path.join(output_folder, dataset)\n",
    "\tif not os.path.exists(folder):\n",
    "\t\traise Exception('Processed Data not found.')\n",
    "\tloader = []\n",
    "\tfor file in ['train', 'test', 'labels']:\n",
    "\t\tif dataset == 'SMD': file = 'machine-1-1_' + file\n",
    "\t\tif dataset == 'SMAP': file = 'P-1_' + file\n",
    "\t\tif dataset == 'MSL': file = 'C-1_' + file\n",
    "\t\tif dataset == 'UCR': file = '136_' + file\n",
    "\t\tif dataset == 'NAB': file = 'ec2_request_latency_system_failure_' + file\n",
    "\t\tloader.append(np.load(os.path.join(folder, f'{file}.npy')))\n",
    "\t# loader = [i[:, debug:debug+1] for i in loader]\n",
    "\tif args.less: loader[0] = cut_array(0.2, loader[0])\n",
    "\ttrain_loader = DataLoader(loader[0], batch_size=loader[0].shape[0])\n",
    "\ttest_loader = DataLoader(loader[1], batch_size=loader[1].shape[0])\n",
    "\tlabels = loader[2]\n",
    "\treturn train_loader, test_loader, labels\n",
    "\n",
    "def save_model(model, optimizer, scheduler, epoch, accuracy_list):\n",
    "\tfolder = f'checkpoints/{args.model}_{args.dataset}/'\n",
    "\tos.makedirs(folder, exist_ok=True)\n",
    "\tfile_path = f'{folder}/model.ckpt'\n",
    "\ttorch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'accuracy_list': accuracy_list}, file_path)\n",
    "\n",
    "def load_model(modelname, dims):\n",
    "\timport src.models\n",
    "\tmodel_class = getattr(src.models, modelname)\n",
    "\tmodel = model_class(dims).double()\n",
    "\toptimizer = torch.optim.AdamW(model.parameters() , lr=model.lr, weight_decay=1e-5)\n",
    "\tscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5, 0.9)\n",
    "\tfname = f'checkpoints/{args.model}_{args.dataset}/model.ckpt'\n",
    "\tif os.path.exists(fname) and (not args.retrain or args.test):\n",
    "\t\tprint(f\"{color.GREEN}Loading pre-trained model: {model.name}{color.ENDC}\")\n",
    "\t\tcheckpoint = torch.load(fname)\n",
    "\t\tmodel.load_state_dict(checkpoint['model_state_dict'])\n",
    "\t\toptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\t\tscheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\t\tepoch = checkpoint['epoch']\n",
    "\t\taccuracy_list = checkpoint['accuracy_list']\n",
    "\telse:\n",
    "\t\tprint(f\"{color.GREEN}Creating new model: {model.name}{color.ENDC}\")\n",
    "\t\tepoch = -1; accuracy_list = []\n",
    "\treturn model, optimizer, scheduler, epoch, accuracy_list\n",
    "\n",
    "def backprop(epoch, model, data, dataO, optimizer, scheduler, training = True):\n",
    "\tl = nn.MSELoss(reduction = 'mean' if training else 'none')\n",
    "\tfeats = dataO.shape[1]\n",
    "\tif 'DAGMM' in model.name:\n",
    "\t\tl = nn.MSELoss(reduction = 'none')\n",
    "\t\tcompute = ComputeLoss(model, 0.1, 0.005, 'cpu', model.n_gmm)\n",
    "\t\tn = epoch + 1; w_size = model.n_window\n",
    "\t\tl1s = []; l2s = []\n",
    "\t\tif training:\n",
    "\t\t\tfor d in data:\n",
    "\t\t\t\t_, x_hat, z, gamma = model(d)\n",
    "\t\t\t\tl1, l2 = l(x_hat, d), l(gamma, d)\n",
    "\t\t\t\tl1s.append(torch.mean(l1).item()); l2s.append(torch.mean(l2).item())\n",
    "\t\t\t\tloss = torch.mean(l1) + torch.mean(l2)\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\tscheduler.step()\n",
    "\t\t\ttqdm.write(f'Epoch {epoch},\\tL1 = {np.mean(l1s)},\\tL2 = {np.mean(l2s)}')\n",
    "\t\t\treturn np.mean(l1s)+np.mean(l2s), optimizer.param_groups[0]['lr']\n",
    "\t\telse:\n",
    "\t\t\tae1s = []\n",
    "\t\t\tfor d in data: \n",
    "\t\t\t\t_, x_hat, _, _ = model(d)\n",
    "\t\t\t\tae1s.append(x_hat)\n",
    "\t\t\tae1s = torch.stack(ae1s)\n",
    "\t\t\ty_pred = ae1s[:, data.shape[1]-feats:data.shape[1]].view(-1, feats)\n",
    "\t\t\tloss = l(ae1s, data)[:, data.shape[1]-feats:data.shape[1]].view(-1, feats)\n",
    "\t\t\treturn loss.detach().numpy(), y_pred.detach().numpy()\n",
    "\tif 'Attention' in model.name:\n",
    "\t\tl = nn.MSELoss(reduction = 'none')\n",
    "\t\tn = epoch + 1; w_size = model.n_window\n",
    "\t\tl1s = []; res = []\n",
    "\t\tif training:\n",
    "\t\t\tfor d in data:\n",
    "\t\t\t\tae, ats = model(d)\n",
    "\t\t\t\t# res.append(torch.mean(ats, axis=0).view(-1))\n",
    "\t\t\t\tl1 = l(ae, d)\n",
    "\t\t\t\tl1s.append(torch.mean(l1).item())\n",
    "\t\t\t\tloss = torch.mean(l1)\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\t# res = torch.stack(res); np.save('ascores.npy', res.detach().numpy())\n",
    "\t\t\tscheduler.step()\n",
    "\t\t\ttqdm.write(f'Epoch {epoch},\\tL1 = {np.mean(l1s)}')\n",
    "\t\t\treturn np.mean(l1s), optimizer.param_groups[0]['lr']\n",
    "\t\telse:\n",
    "\t\t\tae1s, y_pred = [], []\n",
    "\t\t\tfor d in data: \n",
    "\t\t\t\tae1 = model(d)\n",
    "\t\t\t\ty_pred.append(ae1[-1])\n",
    "\t\t\t\tae1s.append(ae1)\n",
    "\t\t\tae1s, y_pred = torch.stack(ae1s), torch.stack(y_pred)\n",
    "\t\t\tloss = torch.mean(l(ae1s, data), axis=1)\n",
    "\t\t\treturn loss.detach().numpy(), y_pred.detach().numpy()\n",
    "\telif 'OmniAnomaly' in model.name:\n",
    "\t\tif training:\n",
    "\t\t\tmses, klds = [], []\n",
    "\t\t\tfor i, d in enumerate(data):\n",
    "\t\t\t\ty_pred, mu, logvar, hidden = model(d, hidden if i else None)\n",
    "\t\t\t\tMSE = l(y_pred, d)\n",
    "\t\t\t\tKLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=0)\n",
    "\t\t\t\tloss = MSE + model.beta * KLD\n",
    "\t\t\t\tmses.append(torch.mean(MSE).item()); klds.append(model.beta * torch.mean(KLD).item())\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\ttqdm.write(f'Epoch {epoch},\\tMSE = {np.mean(mses)},\\tKLD = {np.mean(klds)}')\n",
    "\t\t\tscheduler.step()\n",
    "\t\t\treturn loss.item(), optimizer.param_groups[0]['lr']\n",
    "\t\telse:\n",
    "\t\t\ty_preds = []\n",
    "\t\t\tfor i, d in enumerate(data):\n",
    "\t\t\t\ty_pred, _, _, hidden = model(d, hidden if i else None)\n",
    "\t\t\t\ty_preds.append(y_pred)\n",
    "\t\t\ty_pred = torch.stack(y_preds)\n",
    "\t\t\tMSE = l(y_pred, data)\n",
    "\t\t\treturn MSE.detach().numpy(), y_pred.detach().numpy()\n",
    "\telif 'USAD' in model.name:\n",
    "\t\tl = nn.MSELoss(reduction = 'none')\n",
    "\t\tn = epoch + 1; w_size = model.n_window\n",
    "\t\tl1s, l2s = [], []\n",
    "\t\tif training:\n",
    "\t\t\tfor d in data:\n",
    "\t\t\t\tae1s, ae2s, ae2ae1s = model(d)\n",
    "\t\t\t\tl1 = (1 / n) * l(ae1s, d) + (1 - 1/n) * l(ae2ae1s, d)\n",
    "\t\t\t\tl2 = (1 / n) * l(ae2s, d) - (1 - 1/n) * l(ae2ae1s, d)\n",
    "\t\t\t\tl1s.append(torch.mean(l1).item()); l2s.append(torch.mean(l2).item())\n",
    "\t\t\t\tloss = torch.mean(l1 + l2)\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\tscheduler.step()\n",
    "\t\t\ttqdm.write(f'Epoch {epoch},\\tL1 = {np.mean(l1s)},\\tL2 = {np.mean(l2s)}')\n",
    "\t\t\treturn np.mean(l1s)+np.mean(l2s), optimizer.param_groups[0]['lr']\n",
    "\t\telse:\n",
    "\t\t\tae1s, ae2s, ae2ae1s = [], [], []\n",
    "\t\t\tfor d in data: \n",
    "\t\t\t\tae1, ae2, ae2ae1 = model(d)\n",
    "\t\t\t\tae1s.append(ae1); ae2s.append(ae2); ae2ae1s.append(ae2ae1)\n",
    "\t\t\tae1s, ae2s, ae2ae1s = torch.stack(ae1s), torch.stack(ae2s), torch.stack(ae2ae1s)\n",
    "\t\t\ty_pred = ae1s[:, data.shape[1]-feats:data.shape[1]].view(-1, feats)\n",
    "\t\t\tloss = 0.1 * l(ae1s, data) + 0.9 * l(ae2ae1s, data)\n",
    "\t\t\tloss = loss[:, data.shape[1]-feats:data.shape[1]].view(-1, feats)\n",
    "\t\t\treturn loss.detach().numpy(), y_pred.detach().numpy()\n",
    "\telif model.name in ['GDN', 'MTAD_GAT', 'MSCRED', 'CAE_M']:\n",
    "\t\tl = nn.MSELoss(reduction = 'none')\n",
    "\t\tn = epoch + 1; w_size = model.n_window\n",
    "\t\tl1s = []\n",
    "\t\tif training:\n",
    "\t\t\tfor i, d in enumerate(data):\n",
    "\t\t\t\tif 'MTAD_GAT' in model.name: \n",
    "\t\t\t\t\tx, h = model(d, h if i else None)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx = model(d)\n",
    "\t\t\t\tloss = torch.mean(l(x, d))\n",
    "\t\t\t\tl1s.append(torch.mean(loss).item())\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\ttqdm.write(f'Epoch {epoch},\\tMSE = {np.mean(l1s)}')\n",
    "\t\t\treturn np.mean(l1s), optimizer.param_groups[0]['lr']\n",
    "\t\telse:\n",
    "\t\t\txs = []\n",
    "\t\t\tfor d in data: \n",
    "\t\t\t\tif 'MTAD_GAT' in model.name: \n",
    "\t\t\t\t\tx, h = model(d, None)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx = model(d)\n",
    "\t\t\t\txs.append(x)\n",
    "\t\t\txs = torch.stack(xs)\n",
    "\t\t\ty_pred = xs[:, data.shape[1]-feats:data.shape[1]].view(-1, feats)\n",
    "\t\t\tloss = l(xs, data)\n",
    "\t\t\tloss = loss[:, data.shape[1]-feats:data.shape[1]].view(-1, feats)\n",
    "\t\t\treturn loss.detach().numpy(), y_pred.detach().numpy()\n",
    "\telif 'GAN' in model.name:\n",
    "\t\tl = nn.MSELoss(reduction = 'none')\n",
    "\t\tbcel = nn.BCELoss(reduction = 'mean')\n",
    "\t\tmsel = nn.MSELoss(reduction = 'mean')\n",
    "\t\treal_label, fake_label = torch.tensor([0.9]), torch.tensor([0.1]) # label smoothing\n",
    "\t\treal_label, fake_label = real_label.type(torch.DoubleTensor), fake_label.type(torch.DoubleTensor)\n",
    "\t\tn = epoch + 1; w_size = model.n_window\n",
    "\t\tmses, gls, dls = [], [], []\n",
    "\t\tif training:\n",
    "\t\t\tfor d in data:\n",
    "\t\t\t\t# training discriminator\n",
    "\t\t\t\tmodel.discriminator.zero_grad()\n",
    "\t\t\t\t_, real, fake = model(d)\n",
    "\t\t\t\tdl = bcel(real, real_label) + bcel(fake, fake_label)\n",
    "\t\t\t\tdl.backward()\n",
    "\t\t\t\tmodel.generator.zero_grad()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\t\t# training generator\n",
    "\t\t\t\tz, _, fake = model(d)\n",
    "\t\t\t\tmse = msel(z, d) \n",
    "\t\t\t\tgl = bcel(fake, real_label)\n",
    "\t\t\t\ttl = gl + mse\n",
    "\t\t\t\ttl.backward()\n",
    "\t\t\t\tmodel.discriminator.zero_grad()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\t\tmses.append(mse.item()); gls.append(gl.item()); dls.append(dl.item())\n",
    "\t\t\t\t# tqdm.write(f'Epoch {epoch},\\tMSE = {mse},\\tG = {gl},\\tD = {dl}')\n",
    "\t\t\ttqdm.write(f'Epoch {epoch},\\tMSE = {np.mean(mses)},\\tG = {np.mean(gls)},\\tD = {np.mean(dls)}')\n",
    "\t\t\treturn np.mean(gls)+np.mean(dls), optimizer.param_groups[0]['lr']\n",
    "\t\telse:\n",
    "\t\t\toutputs = []\n",
    "\t\t\tfor d in data: \n",
    "\t\t\t\tz, _, _ = model(d)\n",
    "\t\t\t\toutputs.append(z)\n",
    "\t\t\toutputs = torch.stack(outputs)\n",
    "\t\t\ty_pred = outputs[:, data.shape[1]-feats:data.shape[1]].view(-1, feats)\n",
    "\t\t\tloss = l(outputs, data)\n",
    "\t\t\tloss = loss[:, data.shape[1]-feats:data.shape[1]].view(-1, feats)\n",
    "\t\t\treturn loss.detach().numpy(), y_pred.detach().numpy()\n",
    "\telif 'TranAD' in model.name:\n",
    "\t\tl = nn.MSELoss(reduction = 'none')\n",
    "\t\tdata_x = torch.DoubleTensor(data); dataset = TensorDataset(data_x, data_x)\n",
    "\t\tbs = model.batch if training else len(data)\n",
    "\t\tdataloader = DataLoader(dataset, batch_size = bs)\n",
    "\t\tn = epoch + 1; w_size = model.n_window\n",
    "\t\tl1s, l2s = [], []\n",
    "\t\tif training:\n",
    "\t\t\tfor d, _ in dataloader:\n",
    "\t\t\t\tlocal_bs = d.shape[0]\n",
    "\t\t\t\twindow = d.permute(1, 0, 2)\n",
    "\t\t\t\telem = window[-1, :, :].view(1, local_bs, feats)\n",
    "\t\t\t\tz = model(window, elem)\n",
    "\t\t\t\tl1 = l(z, elem) if not isinstance(z, tuple) else (1 / n) * l(z[0], elem) + (1 - 1/n) * l(z[1], elem)\n",
    "\t\t\t\tif isinstance(z, tuple): z = z[1]\n",
    "\t\t\t\tl1s.append(torch.mean(l1).item())\n",
    "\t\t\t\tloss = torch.mean(l1)\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tloss.backward(retain_graph=True)\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\tscheduler.step()\n",
    "\t\t\ttqdm.write(f'Epoch {epoch},\\tL1 = {np.mean(l1s)}')\n",
    "\t\t\treturn np.mean(l1s), optimizer.param_groups[0]['lr']\n",
    "\t\telse:\n",
    "\t\t\tfor d, _ in dataloader:\n",
    "\t\t\t\twindow = d.permute(1, 0, 2)\n",
    "\t\t\t\telem = window[-1, :, :].view(1, bs, feats)\n",
    "\t\t\t\tz = model(window, elem)\n",
    "\t\t\t\tif isinstance(z, tuple): z = z[1]\n",
    "\t\t\tloss = l(z, elem)[0]\n",
    "\t\t\treturn loss.detach().numpy(), z.detach().numpy()[0]\n",
    "\telse:\n",
    "\t\ty_pred = model(data)\n",
    "\t\tloss = l(y_pred, data)\n",
    "\t\tif training:\n",
    "\t\t\ttqdm.write(f'Epoch {epoch},\\tMSE = {loss}')\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tscheduler.step()\n",
    "\t\t\treturn loss.item(), optimizer.param_groups[0]['lr']\n",
    "\t\telse:\n",
    "\t\t\treturn loss.detach().numpy(), y_pred.detach().numpy()\n",
    "\n",
    "def main_tranad(args):\n",
    "\ttrain_loader, test_loader, labels = load_dataset(args.dataset)\n",
    "\tif args.model in ['MERLIN']:\n",
    "\t\teval(f'run_{args.model.lower()}(test_loader, labels, args.dataset)')\n",
    "\tmodel, optimizer, scheduler, epoch, accuracy_list = load_model(args.model, labels.shape[1])\n",
    "\n",
    "\t## Prepare data\n",
    "\ttrainD, testD = next(iter(train_loader)), next(iter(test_loader))\n",
    "\ttrainO, testO = trainD, testD\n",
    "\tif model.name in ['Attention', 'DAGMM', 'USAD', 'MSCRED', 'CAE_M', 'GDN', 'MTAD_GAT', 'MAD_GAN'] or 'TranAD' in model.name: \n",
    "\t\ttrainD, testD = convert_to_windows(trainD, model), convert_to_windows(testD, model)\n",
    "\n",
    "\t### Training phase\n",
    "\tif not args.test:\n",
    "\t\tprint(f'{color.HEADER}Training {args.model} on {args.dataset}{color.ENDC}')\n",
    "\t\tnum_epochs = 5; e = epoch + 1; start = time()\n",
    "\t\tfor e in tqdm(list(range(epoch+1, epoch+num_epochs+1))):\n",
    "\t\t\tlossT, lr = backprop(e, model, trainD, trainO, optimizer, scheduler)\n",
    "\t\t\taccuracy_list.append((lossT, lr))\n",
    "\t\tprint(color.BOLD+'Training time: '+\"{:10.4f}\".format(time()-start)+' s'+color.ENDC)\n",
    "\t\tsave_model(model, optimizer, scheduler, e, accuracy_list)\n",
    "\t\tplot_accuracies(accuracy_list, f'{args.model}_{args.dataset}')\n",
    "\n",
    "\t### Testing phase\n",
    "\ttorch.zero_grad = True\n",
    "\tmodel.eval()\n",
    "\tprint(f'{color.HEADER}Testing {args.model} on {args.dataset}{color.ENDC}')\n",
    "\tloss, y_pred = backprop(0, model, testD, testO, optimizer, scheduler, training=False)\n",
    "\n",
    "\t### Plot curves\n",
    "\tif not args.test:\n",
    "\t\tif 'TranAD' in model.name: testO = torch.roll(testO, 1, 0) \n",
    "\t\tplotter(f'{args.model}_{args.dataset}', testO, y_pred, loss, labels)\n",
    "\n",
    "\t### Scores\n",
    "\tdf = pd.DataFrame()\n",
    "\tlossT, _ = backprop(0, model, trainD, trainO, optimizer, scheduler, training=False)\n",
    "\tfor i in range(loss.shape[1]):\n",
    "\t\tlt, l, ls = lossT[:, i], loss[:, i], labels[:, i]\n",
    "\t\tresult, pred = pot_eval(lt, l, ls); preds.append(pred)\n",
    "\t\tdf = df.append(result, ignore_index=True)\n",
    "\t# preds = np.concatenate([i.reshape(-1, 1) + 0 for i in preds], axis=1)\n",
    "\t# pd.DataFrame(preds, columns=[str(i) for i in range(10)]).to_csv('labels.csv')\n",
    "\tlossTfinal, lossFinal = np.mean(lossT, axis=1), np.mean(loss, axis=1)\n",
    "\tlabelsFinal = (np.sum(labels, axis=1) >= 1) + 0\n",
    "\tresult, _ = pot_eval(lossTfinal, lossFinal, labelsFinal)\n",
    "\tresult.update(hit_att(loss, labels))\n",
    "\tresult.update(ndcg(loss, labels))\n",
    "\tprint(df)\n",
    "\tpprint(result)\n",
    "\t# pprint(getresults2(df, result))\n",
    "\t# beep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = \n",
    "main_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
